目前确定大概基于几个部分

**日志分析**

**用户行为分析**

**文件完整性检查**

**终端检测和响应（EDR）**

后面有想到再加上

## 日志分析

打算分析所有docker的日志

1. **实例化 Kubernetes 客户端**：使用 client-go 库，实例化一个 Kubernetes 客户端。这个客户端将用于查询你集群中所有的 Pod 信息。
2. **获取所有 Pod 信息**：使用 client-go 的 API，你可以获取到你集群中所有的运行的 Pod。你需要的信息包括 Pod 名称，Pod 所在的 Namespace，以及 Pod 下每个容器的名称和ID。
3. **获取容器日志**：在获取每个 Pod 的信息后，你可以通过 Docker API 或者 Kubernetes API 来获取每个容器的日志。使用 Docker API 获取日志时，需要 Docker daemon 的访问权限，通常在运行 Docker 的节点上执行。Kubernetes API 则提供了一个更加便捷的方式，它可以透明的获取到你 Pod 下所有容器的日志。
4. **处理日志**：获取到日志后，你可能需要对日志进行一些处理，比如过滤、格式化和加入一些额外的元数据等。你可能还需要将这些日志发送到一些中心日志服务器，比如 ELK、Fluentd 或者是 Loki 等。

> 29/1:遇到的问题：
>
> 在容器环境中执行的命令并不会记录到日志当中，所以无法分析，日志的格式比较难控制，不过还好采用了公共库转化成了每条json的格式
>
> 模型是一个大问题，目前没有可以直接用来调用的模型可以分析日志，有也是python和c的集成化工具，我还开发集贸啊。
>
> 数据库问题，以及数据同步的问题，总不能每次都写一份文件进去吧
>
> 打算： [k8s恶意行为检测.md](k8s恶意行为检测.md) 
>
> 先把json文件转化到数据库里面，不过我是每一条解析的，可能还是有点困难
>
> 数据同步，有没有可能我可以把数据写到一个变量的文件，再把该文件写进去覆盖数据库，这样可能会占用大量的资源。我想到的还有一个方法是用时间戳，pod肯定是要重新遍历的，不过怎么获取到那个时间之后的日志呢？(如果能覆盖文件就好了，不过我的函数是循环处理的，所以覆盖文件显然不可取，只好追加) -->这个其实可以后面来解决，先采用两次覆盖的形式好了（文件的位置也是个问题，毕竟涉及到后面的部署）
>
> 模型的训练，是不是要重新训练一个模型，用什么基础模型(GPT3.5?)，训练的资源从哪儿来，用什么数据库
>
> 感觉前途艰险，时间也很紧张

总结一下：

21/2

整了很多东西，也搞了很多没用的

最后的实现的思路是

go这边写了一个所有pod日志抓取 + 规则过滤提取恶意日志，并写到数据库里添加标签的操作

python这边通过写ebpf监控内核调用 + 目录挂载实现了检测容器执行的shell,通过规则过滤一次判断，通过ai进行二次判断来形成恶意shell行为，并写到数据库里面。

 ai是在预训练模型distilbert-base-uncased的基础上进行微调，采用自己标注的预训练数据，并且进行了概率的判断。

此后只需要用前端调用数据库即可。